---
output:
  html_document: default
  pdf_document: default
  word_document: default
---

title: "Assignment - Artificial Neural Networks "
Homework 7
Stat 6620
Section - 1
Asati Surabhi


#Question 1: Perform the ANN analysis on the concrete data. Produce a report explaining the data, the analysis, and the findings.

#ANN analysis on the concrete data   

```{r}

##### Part 1: Neural Networks -------------------
## Example: Modeling the Strength of Concrete  ----

## Step 1: Collecting the data ----
# read in data and examine structure
concrete <- read.csv("concrete.csv")
str(concrete)
```


## Step 2: Exploring and Preparing the data ----
#The nine variables in the data frame correspond to the eight features and one outcome. 
#Neural networks work best when the input data are scaled to a narrow range around zero, and here we see values ranging anywhere from zero up to over a thousand. Therefore, we would normalize the data.


```{r}

#Examine the ranges
summary(concrete)

# custom normalization function
normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}

# apply normalization to entire data frame
concrete_norm <- as.data.frame(lapply(concrete, normalize))

# confirm that the range is now between zero and one
summary(concrete_norm$strength)

# compared to the original minimum and maximum
summary(concrete$strength)

# create training and test data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
```
## Step 3: Training a model on the data ----
To model the relationship between the ingredients used in concrete and the strength
of the finished product, we are using a multilayer feedforward neural network

```{r}

# train the neuralnet model
library(neuralnet)

# simple ANN with only a single hidden neuron
set.seed(12345) # to guarantee repeatable results
concrete_model <- neuralnet(formula = strength ~ cement + slag +
                              ash + water + superplastic + 
                              coarseagg + fineagg + age,
                              data = concrete_train)

# visualize the network topology
plot(concrete_model)


library(NeuralNetTools)

# plotnet
par(mar = numeric(4), family = 'serif')
plotnet(concrete_model, alpha = 0.6)
```

#number of training steps    =  4882
#Sum of Squared Errors (SSE) =  5.077
#A lower SSE implies  better model performance on training data. 5.077 is  clearly very high.

```{r}
## Step 4: Evaluating model performance ----
# obtain model results

model_results <- compute(concrete_model, concrete_test[1:8])
# obtain predicted strength values
predicted_strength <- model_results$net.result
# examine the correlation between predicted and actual values
cor(predicted_strength, concrete_test$strength) 

# produce actual predictions by 

head(predicted_strength)

concrete_train_original_strength <- concrete[1:773,"strength"]

strength_min <- min(concrete_train_original_strength)
strength_max <- max(concrete_train_original_strength)

head(concrete_train_original_strength)

# custom normalization function
unnormalize <- function(x, min, max) { 
  return( (max - min)*x + min )
}

strength_pred <- unnormalize(predicted_strength, strength_min, strength_max)

summary(strength_pred)
```
#Correlation = 0.806

```{r}
## Step 5: Improving model performance ----
# a more complex neural network topology with 5 hidden neurons
set.seed(12345) # to guarantee repeatable results
concrete_model2 <- neuralnet(strength ~ cement + slag +
                               ash + water + superplastic + 
                               coarseagg + fineagg + age,
                               data = concrete_train, hidden = 5, act.fct = "logistic")

# plot the network
plot(concrete_model2)

# plotnet
par(mar = numeric(4), family = 'serif')
plotnet(concrete_model2, alpha = 0.6)

# evaluate the results as we did before
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength)
```
#number of training steps    =  86849
#Sum of Squared Errors (SSE) =  1.63
#The error has been reduced from 5.077 to 1.63 which indicates better predicted performance.
#Also, the number of training stps has rose from 4,882 to 86,849 that shows the model has become more complex i.e. it takes more iterations to find the optimal weights.

#Correlation = 0.924, higher than 0.806 (model with single hidden layer)

# Trying different activation function to improve accuracy 

```{r}

# a more complex neural network topology with 5 hidden neurons
set.seed(12345) # to guarantee repeatable results
concrete_model2 <- neuralnet(strength ~ cement + slag +
                               ash + water + superplastic + 
                               coarseagg + fineagg + age,
                             data = concrete_train, hidden = 5, act.fct = "tanh")

# evaluate the results as we did before
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength) 
```
#Correlation = 0.574. dropped from model with activation function = Logistic. 




#Question 2: Develop an ANN for the redwines.csv data from Homework 5. Produce a report using an Rnotebook explaining the data, the analysis, and the findings.

```{r}
## Step 1: Collecting the data ----
# read in data and examine structure
redwines <- read.csv("redwines1.csv")
str(redwines)
```

```{r}
## Step 2: Exploring and Preparing the data ----
#Examine the ranges
summary(redwines)

# the distribution of quality ratings
hist(redwines$quality)

# custom normalization function
normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}

# apply normalization to entire data frame
redwines_norm <- as.data.frame(lapply(redwines, normalize))

# confirm that the range is now between zero and one
summary(redwines_norm$quality)

# compared to the original minimum and maximum
summary(redwines$quality)

# create training and test data
redwines_train <- redwines_norm[1:1199, ]
redwines_test <- redwines_norm[1200:1599, ]
```

## Step 3: Training a model on the data ----

```{r}

# train the neuralnet model
library(neuralnet)

# simple ANN with only a single hidden neuron
set.seed(12345) # to guarantee repeatable results
redwines_model <- neuralnet(formula = quality ~ fixed.acidity + volatile.acidity +
                              citric.acid + residual.sugar + chlorides + 
                              free.sulfur.dioxide + total.sulfur.dioxide + density + pH +                                   sulphates + alcohol,
                              data = redwines_train)

# visualize the network topology
plot(redwines_model)

# alternative plot
library(NeuralNetTools) 

# plotnet
par(mar = numeric(4), family = 'serif')
plotnet(redwines_model, alpha = 0.6)
```
#number of training steps    =  1266
#Sum of Squared Errors (SSE) =  10.1


## Step 4: Evaluating model performance ----

```{r}

# obtain model results
model_results <- compute(redwines_model, redwines_test[1:11])

# obtain predicted strength values
predicted_quality <- model_results$net.result

# examine the correlation between predicted and actual values
cor(predicted_quality, redwines_test$quality) 

# produce actual predictions by 

head(predicted_quality)

redwines_train_original_quality <- redwines[1:1199,"quality"]

quality_min <- min(redwines_train_original_quality)
quality_max <- max(redwines_train_original_quality)

head(redwines_train_original_quality)

# custom normalization function
unnormalize <- function(x, min, max) { 
  return( (max - min)*x + min )
}

quality_pred <- unnormalize(predicted_quality, quality_min, quality_max)
summary(quality_pred)
```
#Correlation = 0.669
#The correlation has a lot of scope of improvement
#As networks with more complex topologies are capable of learning more difficult
#concepts, we will try to increase the number of hidden nodes to 5

## Step 5: Improving model performance ----
```{r}

# A more complex neural network topology with 5 hidden neurons
set.seed(12345) # to guarantee repeatable results
redwines_model2 <- neuralnet(formula = quality ~ fixed.acidity + volatile.acidity +
                              citric.acid + residual.sugar + chlorides + 
                              free.sulfur.dioxide + total.sulfur.dioxide + density + pH +                                   sulphates + alcohol,
                              data = redwines_train, hidden = 5, act.fct = "logistic")

# plot the network
plot(redwines_model2)

# plotnet
par(mar = numeric(4), family = 'serif')
plotnet(redwines_model2, alpha = 0.6)

# evaluate the results as we did before
model_results2 <- compute(redwines_model2, redwines_test[1:11])
predicted_quality2 <- model_results2$net.result
cor(predicted_quality2, redwines_test$quality)  
```

#The correlation has improved to 0.674 with more complex network topology.

```{r}
# try different activation function
# a more complex neural network topology with 5 hidden neurons
set.seed(12345) # to guarantee repeatable results
redwines_model2 <- neuralnet(formula = quality ~ fixed.acidity + volatile.acidity +
                              citric.acid + residual.sugar + chlorides + 
                              free.sulfur.dioxide + total.sulfur.dioxide + density + pH +                                   sulphates + alcohol,
                              data = redwines_train, hidden = 5, act.fct = "tanh")

# evaluate the results as we did before
model_results2 <- compute(redwines_model2, redwines_test[1:11])
predicted_quality2 <- model_results2$net.result
cor(predicted_quality2, redwines_test$quality) 
```
#The correlation has further improved to 0.717 with more complex network topology and a different activation function - tanh.





#Question 3: Read the blog post Multilable classification with neuralnet package and run the code.

```{r}
#Multilabel classification with neuralnet package

# load libs
require(neuralnet)
require(nnet)
require(ggplot2)
set.seed(10)


```

#The dataset
#From UCI Machine Learning Repository - wine dataset.

#This dataset contains the results of a chemical analysis on 3 different kind of wines. 
#The target variable is the label of the wine which is a factor with 3 (unordered) levels. 
#The predictors are all continuous and represent 13 variables obtained as a result of chemical measurements.


#Step 1: Loading the data---------

```{r}
# Load data and set variables names
wines <- read.csv("wines.csv")
names(wines) <- c("label",
                  "Alcohol",
                  "Malic_acid",
                  "Ash",
                  "Alcalinity_of_ash",
                  "Magnesium",
                  "Total_phenols",
                  "Flavanoids",
                  "Nonflavanoid_phenols",
                  "Proanthocyanins",
                  "Color_intensity",
                  "Hue",
                  "OD280_OD315_of_diluted_wines",
                  "Proline")
head(wines)
str(wines)

#Visualize the data
plt1 <- ggplot(wines, aes(x = Alcohol, y = Magnesium, colour = as.factor(label))) +
  geom_point(size=3) +
  ggtitle("Wines")

plt2 <- ggplot(wines, aes(x = Alcohol, y = Proline, colour = as.factor(label))) +
  geom_point(size=3) +
  ggtitle("Wines")

plt1
plt2
```

#Step 2: Preprocessing---------

```{r}
# A. Encode target variable as a one hot vector multilabel data
#The encoding of the categorical variables is needed when using neuralnet
#since it does not like factors at all.

train <- cbind(wines[, 2:14], class.ind(as.factor(wines$label)))

# Set labels name
names(train) <- c(names(wines)[2:14],"l1","l2","l3")

# B. Standardize the predictors
# Scale data
scl <- function(x){ (x - min(x))/(max(x) - min(x)) }
train[, 1:13] <- data.frame(lapply(train[, 1:13], scl))
head(train)

```


#Step 3: Fitting the model with neuralnet---------

```{r}
# Set up formula as neuralnet does not like the formula y~.
n <- names(train)
f <- as.formula(paste("l1 + l2 + l3 ~", paste(n[!n %in% c("l1","l2","l3")], collapse = " + ")))
f

#train the neural network with the full dataset

nn <- neuralnet(f,
                data = train,
                hidden = c(13, 10, 3),
                act.fct = "logistic",
                linear.output = FALSE,
                lifesign = "minimal")

#Plotting the model
plot(nn)

```


#Step 4: Evaluating model performance---------

```{r}
# Compute predictions
pr.nn <- compute(nn, train[, 1:13])

# Extract results
pr.nn_ <- pr.nn$net.result
head(pr.nn_)


# Accuracy (training set)
original_values <- max.col(train[, 14:16])
pr.nn_2 <- max.col(pr.nn_)
mean(pr.nn_2 == original_values)

```
#100% accuracy! this may be because the model over fitted the data.
#In order to assess the ???true accuracy??? of the model we need to perform cross validation.


# Step 5: Improving model performance----------

```{r}
#Cross Validation

# Set seed for reproducibility purposes
set.seed(500)

# 10 fold cross validation
k <- 10

# Results from cv
outs <- NULL

# Train test split proportions
#95% of the dataset will be used as training set while the remaining 5% as test set.
proportion <- 0.95 # Set to 0.995 for LOOCV

# Crossvalidate, go!
for(i in 1:k)
{
  index <- sample(1:nrow(train), round(proportion*nrow(train)))
  train_cv <- train[index, ]
  test_cv <- train[-index, ]
  nn_cv <- neuralnet(f,
                     data = train_cv,
                     hidden = c(13, 10, 3),
                     act.fct = "logistic",
                     linear.output = FALSE)

  # Compute predictions
  pr.nn <- compute(nn_cv, test_cv[, 1:13])
  # Extract results
  pr.nn_ <- pr.nn$net.result
  # Accuracy (test set)
  original_values <- max.col(test_cv[, 14:16])
  pr.nn_2 <- max.col(pr.nn_)
  outs[i] <- mean(pr.nn_2 == original_values)
}

mean(outs)


```

#Accuracy = 98.8%